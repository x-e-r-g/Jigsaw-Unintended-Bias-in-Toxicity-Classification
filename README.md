
# ANALYSIS OF UNINTENDED BIAS IN TOXICITY

This project uses multiple cleaning techniques to clean the text data which fed to a logistic regression model to predict toxicity of public comments in the online platform.

## Description

The [competition](https://www.kaggle.com/c/jigsaw-unintended-bias-in-toxicity-classification/overview) is a challenge to build a model that recognizes toxicity and minimizes the unintended bias with respect to mentions of identities. Competitors are asked to develop strategies to reduce unintended bias in machine learning models, and help the Conversation AI team, and the entire industry to build models that work well for a wide range of conversations.

## Authors

Contributors names and contact info

Zubair Rahman Tusar [@zubairrahmantusar](https://www.kaggle.com/zubairrahmantusar)

## Acknowledgments

Inspiration, code snippets, etc.
* [Cleaning Process](https://www.kaggle.com/uysimty/simple-toxicity-classification)
* [Text to Matrix](https://www.kaggle.com/arthurtok/spooky-nlp-and-topic-modelling-tutorial)